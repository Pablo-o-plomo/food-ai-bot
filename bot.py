import os
import base64
from dotenv import load_dotenv
from openai import OpenAI
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

load_dotenv()

TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")

client = OpenAI(api_key=OPENAI_KEY)

# ---------------- SETTINGS ----------------

MODEL = "gpt-4o"
MAX_HISTORY = 12  # –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏ –¥–∏–∞–ª–æ–≥–∞

# ---------------- MEMORY ----------------

user_sessions = {}

SYSTEM_PROMPT = """
–¢—ã –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π AI-–Ω—É—Ç—Ä–∏—Ü–∏–æ–ª–æ–≥ –∏ –∫–æ—É—á.
–¢—ã —É–º–µ–µ—à—å:
- —Å–æ—Å—Ç–∞–≤–ª—è—Ç—å –ø–ª–∞–Ω –ø–∏—Ç–∞–Ω–∏—è
- —Å—á–∏—Ç–∞—Ç—å –∫–∞–ª–æ—Ä–∏–∏
- –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–æ—Ç–æ –µ–¥—ã
- –ø–æ–º–æ–≥–∞—Ç—å –≤ –ø–æ—Ö—É–¥–µ–Ω–∏–∏
- –¥–∞–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã

–û—Ç–≤–µ—á–∞–π –ø–æ–Ω—è—Ç–Ω–æ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ –∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ.
"""

# ---------------- UTIL ----------------

def trim_history(history):
    if len(history) > MAX_HISTORY:
        return [history[0]] + history[-MAX_HISTORY:]
    return history

# ---------------- HANDLERS ----------------

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "GPT-–Ω—É—Ç—Ä–∏—Ü–∏–æ–ª–æ–≥ –∑–∞–ø—É—â–µ–Ω üëå\n–ù–∞–ø–∏—à–∏ —á—Ç–æ —É–≥–æ–¥–Ω–æ –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ –µ–¥—ã."
    )

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):

    try:
        user_id = update.effective_user.id
        text = update.message.text

        if user_id not in user_sessions:
            user_sessions[user_id] = [
                {"role": "system", "content": SYSTEM_PROMPT}
            ]

        user_sessions[user_id].append({"role": "user", "content": text})
        user_sessions[user_id] = trim_history(user_sessions[user_id])

        response = client.chat.completions.create(
            model=MODEL,
            messages=user_sessions[user_id],
            temperature=0.7,
        )

        reply = response.choices[0].message.content

        user_sessions[user_id].append({"role": "assistant", "content": reply})
        user_sessions[user_id] = trim_history(user_sessions[user_id])

        await update.message.reply_text(reply)

    except Exception as e:
        await update.message.reply_text("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞.")
        print("TEXT ERROR:", e)


async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):

    try:
        photo = update.message.photo[-1]
        file = await photo.get_file()
        image_bytes = await file.download_as_bytearray()

        b64_image = base64.b64encode(image_bytes).decode("utf-8")

        response = client.responses.create(
            model="gpt-4.1",
            input=[
                {
                    "role": "system",
                    "content": SYSTEM_PROMPT,
                },
                {
                    "role": "user",
                    "content": [
                        {"type": "input_text", "text": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ñ–æ—Ç–æ –µ–¥—ã."},
                        {
                            "type": "input_image",
                            "image_url": f"data:image/jpeg;base64,{b64_image}",
                        },
                    ],
                },
            ],
            max_output_tokens=500,
        )

        reply = response.output_text

        await update.message.reply_text(reply)

    except Exception as e:
        await update.message.reply_text("–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ñ–æ—Ç–æ.")
        print("PHOTO ERROR:", e)


# ---------------- RUN ----------------

if __name__ == "__main__":

    app = ApplicationBuilder().token(TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_handler(MessageHandler(filters.PHOTO, handle_photo))

    print("PRO GPT –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω üöÄ")
    app.run_polling()